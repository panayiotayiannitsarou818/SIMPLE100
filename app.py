import streamlit as st
import pandas as pd
from io import BytesIO
from datetime import datetime
import re, ast, unicodedata

# ---------------------------
# ğŸ”„ Restart helpers
# ---------------------------
def _restart_app():
    """Clear caches & widget states (including file_uploader) and rerun."""
    st.session_state["uploader_key"] = st.session_state.get("uploader_key", 0) + 1
    for k in list(st.session_state.keys()):
        if str(k).startswith("uploader_"):
            del st.session_state[k]
    try:
        st.cache_data.clear()
    except Exception:
        pass
    try:
        st.cache_resource.clear()
    except Exception:
        pass
    st.rerun()

st.set_page_config(page_title="ğŸ“Š Î£Ï„Î±Ï„Î¹ÏƒÏ„Î¹ÎºÎ¬ & ğŸ§© Î£Ï€Î±ÏƒÎ¼Î­Î½ÎµÏ‚ Î¦Î¹Î»Î¯ÎµÏ‚", page_icon="ğŸ§©", layout="wide")
st.title("ğŸ“Š Î£Ï„Î±Ï„Î¹ÏƒÏ„Î¹ÎºÎ¬")

# Ensure a stable uploader-key in session
if "uploader_key" not in st.session_state:
    st.session_state["uploader_key"] = 0

# ---------------------------
# Sidebar: Legal / Terms + Restart
# ---------------------------
with st.sidebar:
    if st.button("ğŸ”„ Î•Ï€Î±Î½ÎµÎºÎºÎ¯Î½Î·ÏƒÎ· ÎµÏ†Î±ÏÎ¼Î¿Î³Î®Ï‚", help="ÎšÎ±Î¸Î±ÏÎ¯Î¶ÎµÎ¹ Î¼Î½Î®Î¼Î·/Ï†Î¿ÏÏ„ÏÏƒÎµÎ¹Ï‚ ÎºÎ±Î¹ Î¾ÎµÎºÎ¹Î½Î¬ Î±Ï€ÏŒ Ï„Î·Î½ Î±ÏÏ‡Î®"):
        _restart_app()
    st.markdown("### âš–ï¸ ÎŒÏÎ¿Î¹ Ï‡ÏÎ®ÏƒÎ·Ï‚")
    terms_ok = st.checkbox("Î‘Ï€Î¿Î´Î­Ï‡Î¿Î¼Î±Î¹ Ï„Î¿Ï…Ï‚ ÏŒÏÎ¿Ï…Ï‚ Ï‡ÏÎ®ÏƒÎ·Ï‚", value=True)
    st.markdown("Â© 2025 â€¢ Î Î½ÎµÏ…Î¼Î±Ï„Î¹ÎºÎ¬ Î´Î¹ÎºÎ±Î¹ÏÎ¼Î±Ï„Î± â€¢ **Î Î±Î½Î±Î³Î¹ÏÏ„Î± Î“Î¹Î±Î½Î½Î¯Ï„ÏƒÎ±ÏÎ¿Ï…**")

with st.sidebar.expander("ÎšÎ¬Ï„Î¿Ï‡Î¿Ï‚/Î”Î·Î¼Î¹Î¿Ï…ÏÎ³ÏŒÏ‚ & Î†Î´ÎµÎ¹Î±", expanded=False):
    st.markdown("""
**ÎšÎ¬Ï„Î¿Ï‡Î¿Ï‚/Î”Î·Î¼Î¹Î¿Ï…ÏÎ³ÏŒÏ‚:** Î Î±Î½Î±Î³Î¹ÏÏ„Î± Î“Î¹Î±Î½Î½Î¯Ï„ÏƒÎ±ÏÎ¿Ï…  
**Î ÏÎ¿ÏŠÏŒÎ½:** Î£Ï„Î±Ï„Î¹ÏƒÏ„Î¹ÎºÎ¬/ÎšÎ±Ï„Î±Î½Î¿Î¼Î® ÎœÎ±Î¸Î·Ï„ÏÎ½ Î‘Î„ Î”Î·Î¼Î¿Ï„Î¹ÎºÎ¿Ï  

- Î— ÎµÏ†Î±ÏÎ¼Î¿Î³Î® Ï€ÏÎ¿Î¿ÏÎ¯Î¶ÎµÏ„Î±Î¹ Î±Ï€Î¿ÎºÎ»ÎµÎ¹ÏƒÏ„Î¹ÎºÎ¬ Î³Î¹Î± **ÎµÎºÏ€Î±Î¹Î´ÎµÏ…Ï„Î¹ÎºÎ® Ï‡ÏÎ®ÏƒÎ·** Î±Ï€ÏŒ ÏƒÏ‡Î¿Î»Î¹ÎºÎ­Ï‚ Î¼Î¿Î½Î¬Î´ÎµÏ‚/ÎµÎºÏ€Î±Î¹Î´ÎµÏ…Ï„Î¹ÎºÎ¿ÏÏ‚.  
- **Î Î½ÎµÏ…Î¼Î±Ï„Î¹ÎºÎ¬ Î´Î¹ÎºÎ±Î¹ÏÎ¼Î±Ï„Î±:** Â© 2025 Î Î±Î½Î±Î³Î¹ÏÏ„Î± Î“Î¹Î±Î½Î½Î¯Ï„ÏƒÎ±ÏÎ¿Ï…. **Î‘Ï€Î±Î³Î¿ÏÎµÏÎµÏ„Î±Î¹** Î±Î½Ï„Î¹Î³ÏÎ±Ï†Î®, Î±Î½Î±Î´Î·Î¼Î¿ÏƒÎ¯ÎµÏ…ÏƒÎ· Î® Ï„ÏÎ¿Ï€Î¿Ï€Î¿Î¯Î·ÏƒÎ· Ï‡Ï‰ÏÎ¯Ï‚ **Î­Î³Î³ÏÎ±Ï†Î· Î¬Î´ÎµÎ¹Î±**.  
- **ÎœÎ· ÎµÎ¼Ï€Î¿ÏÎ¹ÎºÎ® Ï‡ÏÎ®ÏƒÎ·** ÎµÏ€Î¹Ï„ÏÎ­Ï€ÎµÏ„Î±Î¹ ÏƒÎµ ÏƒÏ‡Î¿Î»ÎµÎ¯Î± Î³Î¹Î± ÎµÏƒÏ‰Ï„ÎµÏÎ¹ÎºÎ® Î¿ÏÎ³Î¬Î½Ï‰ÏƒÎ·.  
- Î Î±ÏÎ­Ï‡ÎµÏ„Î±Î¹ â€œ**Ï‰Ï‚ Î­Ï‡ÎµÎ¹**â€ Ï‡Ï‰ÏÎ¯Ï‚ ÎµÎ³Î³Ï…Î®ÏƒÎµÎ¹Ï‚. Î¤Î± Î±Ï€Î¿Ï„ÎµÎ»Î­ÏƒÎ¼Î±Ï„Î± Î­Ï‡Î¿Ï…Î½ **Î²Î¿Î·Î¸Î·Ï„Î¹ÎºÏŒ** Ï‡Î±ÏÎ±ÎºÏ„Î®ÏÎ± ÎºÎ±Î¹ **Î´ÎµÎ½ Ï…Ï€Î¿ÎºÎ±Î¸Î¹ÏƒÏ„Î¿ÏÎ½** ÎºÎ±Î½Î¿Î½Î¹ÏƒÏ„Î¹ÎºÎ­Ï‚ Î±Ï€Î¿Ï†Î¬ÏƒÎµÎ¹Ï‚ Î® Ï€Î±Î¹Î´Î±Î³Ï‰Î³Î¹ÎºÎ® ÎºÏÎ¯ÏƒÎ·.  
- **Î•Ï€Î¹ÎºÎ¿Î¹Î½Ï‰Î½Î¯Î±:** panayiotayiannitsarou@gmail.com
""")

with st.sidebar.expander("ğŸ”’ Î ÏÎ¿ÏƒÏ„Î±ÏƒÎ¯Î± Î”ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½ (GDPR â€“ ÎšÏÏ€ÏÎ¿Ï‚)", expanded=False):
    st.markdown("""
- Î¤Î± Î±ÏÏ‡ÎµÎ¯Î± Excel Î±Î½ÎµÎ²Î±Î¯Î½Î¿Ï…Î½ Î±Ï€ÏŒ Ï„Î¿Î½ Ï‡ÏÎ®ÏƒÏ„Î· ÎºÎ±Î¹ Ï‡ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹Î¿ÏÎ½Ï„Î±Î¹ **Î¼ÏŒÎ½Î¿** Î³Î¹Î± Î¬Î¼ÎµÏƒÎ¿ Ï…Ï€Î¿Î»Î¿Î³Î¹ÏƒÎ¼ÏŒ. Î— ÎµÏ†Î±ÏÎ¼Î¿Î³Î® Î´ÎµÎ½ Î±Ï€Î¿Î¸Î·ÎºÎµÏÎµÎ¹ Î¼ÏŒÎ½Î¹Î¼Î± Î´ÎµÎ´Î¿Î¼Î­Î½Î±.  
- ÎŸ Ï‡ÏÎ®ÏƒÏ„Î·Ï‚/ÏƒÏ‡Î¿Î»ÎµÎ¯Î¿ ÎµÏ…Î¸ÏÎ½ÎµÏ„Î±Î¹ Î³Î¹Î± ÏƒÏ…Î¼Î¼ÏŒÏÏ†Ï‰ÏƒÎ· Î¼Îµ **GDPR**.  
- **Î£Ï…ÏƒÏ„Î¬ÏƒÎµÎ¹Ï‚:** ÏˆÎµÏ…Î´ÏÎ½Ï…Î¼Î±/ÎºÏ‰Î´Î¹ÎºÎ¿Î¯, ÎµÎ»Î±Ï‡Î¹ÏƒÏ„Î¿Ï€Î¿Î¯Î·ÏƒÎ· Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½, Ï€ÎµÏÎ¯Î¿Î´Î¿Ï‚ Î´Î¹Î±Ï„Î®ÏÎ·ÏƒÎ·Ï‚, ÎµÎ½Î·Î¼Î­ÏÏ‰ÏƒÎ· DPO, Î­Î»ÎµÎ³Ï‡Î¿Ï‚ Ï€Î±ÏÏŒÏ‡Î¿Ï… cloud.
""")

if not terms_ok:
    st.warning("âš ï¸ Î“Î¹Î± Î½Î± Ï‡ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹Î®ÏƒÎµÎ¹Ï‚ Ï„Î·Î½ ÎµÏ†Î±ÏÎ¼Î¿Î³Î®, Î±Ï€Î¿Î´Î­Î¾Î¿Ï… Ï„Î¿Ï…Ï‚ ÏŒÏÎ¿Ï…Ï‚ Ï‡ÏÎ®ÏƒÎ·Ï‚ (Î±ÏÎ¹ÏƒÏ„ÎµÏÎ¬).")
    st.stop()

with st.expander("ğŸ“œ Î Î»Î®ÏÎµÎ¹Ï‚ ÎŒÏÎ¿Î¹ Î§ÏÎ®ÏƒÎ·Ï‚ & Î‘Ï€Î¿Ï€Î¿Î¯Î·ÏƒÎ· Î•Ï…Î¸ÏÎ½Î·Ï‚", expanded=False):
    st.markdown("""
1) **Î£ÎºÎ¿Ï€ÏŒÏ‚:** Î¥Ï€Î¿ÏƒÏ„Î®ÏÎ¹Î¾Î· ÎµÏƒÏ‰Ï„ÎµÏÎ¹ÎºÎ¿Ï Ï€ÏÎ¿Î³ÏÎ±Î¼Î¼Î±Ï„Î¹ÏƒÎ¼Î¿Ï/ÏƒÏ„Î±Ï„Î¹ÏƒÏ„Î¹ÎºÏÎ½ Ï„Î¬Î¾ÎµÏ‰Î½ Î‘Î„ Î”Î·Î¼Î¿Ï„Î¹ÎºÎ¿Ï.  
2) **Î”ÎµÎ´Î¿Î¼Î­Î½Î±:** Î”ÎµÎ½ Î±Ï€Î¿Î¸Î·ÎºÎµÏÎ¿Î½Ï„Î±Î¹ Î¼ÏŒÎ½Î¹Î¼Î± Î±Ï€ÏŒ Ï„Î·Î½ ÎµÏ†Î±ÏÎ¼Î¿Î³Î®. ÎŸ Ï‡ÏÎ®ÏƒÏ„Î·Ï‚ Ï€Î±ÏÎ±Î¼Î­Î½ÎµÎ¹ Ï…Ï€ÎµÏÎ¸Ï…Î½Î¿Ï‚ Î³Î¹Î± **GDPR**.  
3) **Î ÎµÏÎ¹Î¿ÏÎ¹ÏƒÎ¼Î¿Î¯:** Î‘Ï€Î±Î³Î¿ÏÎµÏÎµÏ„Î±Î¹ ÎµÎ¼Ï€Î¿ÏÎ¹ÎºÎ® ÎµÎºÎ¼ÎµÏ„Î¬Î»Î»ÎµÏ…ÏƒÎ·/Î±Î½Î±Î´Î¹Î±Î½Î¿Î¼Î®/Ï„ÏÎ¿Ï€Î¿Ï€Î¿Î¯Î·ÏƒÎ· Ï‡Ï‰ÏÎ¯Ï‚ Î¬Î´ÎµÎ¹Î±.  
4) **Î‘Ï€Î¿Ï€Î¿Î¯Î·ÏƒÎ·:** Î”ÎµÎ½ Ï…Ï€Î¬ÏÏ‡ÎµÎ¹ ÎµÏ…Î¸ÏÎ½Î· Î³Î¹Î± Î±Ï€Î¿Ï†Î¬ÏƒÎµÎ¹Ï‚ Ï€Î¿Ï… Î»Î±Î¼Î²Î¬Î½Î¿Î½Ï„Î±Î¹ Î±Ï€Î¿ÎºÎ»ÎµÎ¹ÏƒÏ„Î¹ÎºÎ¬ Î¼Îµ Î²Î¬ÏƒÎ· Ï„Î± Î±Ï€Î¿Ï„ÎµÎ»Î­ÏƒÎ¼Î±Ï„Î±.  
5) **Î¤ÏÎ¿Ï€Î¿Ï€Î¿Î¹Î®ÏƒÎµÎ¹Ï‚:** Î— ÎµÏ†Î±ÏÎ¼Î¿Î³Î® Î¼Ï€Î¿ÏÎµÎ¯ Î½Î± ÎµÎ½Î·Î¼ÎµÏÏÎ½ÎµÏ„Î±Î¹ Ï‡Ï‰ÏÎ¯Ï‚ Ï€ÏÎ¿ÎµÎ¹Î´Î¿Ï€Î¿Î¯Î·ÏƒÎ·.
""")

# ---------------------------
# Canonicalization / Renaming
# ---------------------------
def _canon(s: str) -> str:
    return "".join((s or "").replace("_"," ").split()).upper()

CANON_TARGETS = {
    "ÎŸÎÎŸÎœÎ‘": {"ÎŸÎÎŸÎœÎ‘"},
    "Î¦Î¥Î›ÎŸ": {"Î¦Î¥Î›ÎŸ"},
    "Î Î‘Î™Î”Î™_Î•ÎšÎ Î‘Î™Î”Î•Î¥Î¤Î™ÎšÎŸÎ¥": {"Î Î‘Î™Î”Î™Î•ÎšÎ Î‘Î™Î”Î•Î¥Î¤Î™ÎšÎŸÎ¥", "Î Î‘Î™Î”Î™-Î•ÎšÎ Î‘Î™Î”Î•Î¥Î¤Î™ÎšÎŸÎ¥"},
    "Î–Î©Î—Î¡ÎŸÎ£": {"Î–Î©Î—Î¡ÎŸÎ£"},
    "Î™Î”Î™Î‘Î™Î¤Î•Î¡ÎŸÎ¤Î—Î¤Î‘": {"Î™Î”Î™Î‘Î™Î¤Î•Î¡ÎŸÎ¤Î—Î¤Î‘"},
    "ÎšÎ‘Î›Î—_Î“ÎÎ©Î£Î—_Î•Î›Î›Î—ÎÎ™ÎšÎ©Î": {"ÎšÎ‘Î›Î—Î“ÎÎ©Î£Î—Î•Î›Î›Î—ÎÎ™ÎšÎ©Î", "Î“ÎÎ©Î£Î—Î•Î›Î›Î—ÎÎ™ÎšÎ©Î"},
    "Î¦Î™Î›ÎŸÎ™": {"Î¦Î™Î›ÎŸÎ™", "Î¦Î™Î›Î™Î‘", "Î¦Î™Î›ÎŸÎ£"},
    "Î£Î¥Î“ÎšÎ¡ÎŸÎ¥Î£Î—": {"Î£Î¥Î“ÎšÎ¡ÎŸÎ¥Î£Î—", "Î£Î¥Î“ÎšÎ¡ÎŸÎ¥Î£Î•Î™Î£"},
    "Î¤ÎœÎ—ÎœÎ‘": {"Î¤ÎœÎ—ÎœÎ‘"},
}
REQUIRED_COLS = ["ÎŸÎÎŸÎœÎ‘","Î¦Î¥Î›ÎŸ","Î Î‘Î™Î”Î™_Î•ÎšÎ Î‘Î™Î”Î•Î¥Î¤Î™ÎšÎŸÎ¥","Î–Î©Î—Î¡ÎŸÎ£","Î™Î”Î™Î‘Î™Î¤Î•Î¡ÎŸÎ¤Î—Î¤Î‘","ÎšÎ‘Î›Î—_Î“ÎÎ©Î£Î—_Î•Î›Î›Î—ÎÎ™ÎšÎ©Î","Î¦Î™Î›ÎŸÎ™","Î£Î¥Î“ÎšÎ¡ÎŸÎ¥Î£Î—","Î¤ÎœÎ—ÎœÎ‘"]

def auto_rename_columns(df: pd.DataFrame):
    """Map ÎºÎ¿Î¹Î½Î­Ï‚ ÎµÎ»Î»Î·Î½Î¹ÎºÎ­Ï‚ ÏƒÏ„Î®Î»ÎµÏ‚ ÏƒÎµ ÎºÎ±Î½Î¿Î½Î¹ÎºÎ® Î¼Î¿ÏÏ†Î®. Î‘Î½ Î´ÎµÎ½ Î²ÏÎµÎ¸Î¿ÏÎ½, Î´Î·Î¼Î¹Î¿Ï…ÏÎ³Î¿ÏÎ½Ï„Î±Î¹/ÏƒÏ…Î½ÎµÎ½ÏÎ½Î¿Î½Ï„Î±Î¹ ÏŒÏ€Î¿Ï… Ï‡ÏÎµÎ¹Î¬Î¶ÎµÏ„Î±Î¹."""
    mapping, seen = {}, set()
    for col in df.columns:
        c = _canon(col)
        for target, keys in CANON_TARGETS.items():
            if c in keys and target not in seen:
                mapping[col] = target
                seen.add(target)
                break
    renamed = df.rename(columns=mapping)

    # Î¦Î™Î›ÎŸÎ™ fallback
    friends_cols = [c for c in renamed.columns if c in ("Î¦Î™Î›ÎŸÎ™","Î¦Î™Î›Î™Î‘","Î¦Î™Î›ÎŸÎ£")]
    if not friends_cols:
        candidates = []
        for col in df.columns:
            c = _canon(col)
            if "Î¦Î™Î›" in c or "FRIEND" in c:
                candidates.append(col)
        if candidates:
            combined = []
            for _, row in df[candidates].astype(str).iterrows():
                vals = [str(v).strip() for v in row.tolist() if str(v).strip() and str(v).strip().upper() not in ("-","NA","NAN")]
                combined.append(", ".join(vals))
            renamed["Î¦Î™Î›ÎŸÎ™"] = combined

    # Î¤ÎœÎ—ÎœÎ‘ fallback
    if "Î¤ÎœÎ—ÎœÎ‘" not in renamed.columns:
        best = None
        for col in df.columns[::-1]:
            s = df[col].dropna().astype(str).str.strip()
            if not len(s):
                continue
            if s.str.len().median() <= 4 and s.nunique() <= 10:
                best = col
                break
        if best:
            renamed = renamed.rename(columns={best:"Î¤ÎœÎ—ÎœÎ‘"})

    # Î£Î¥Î“ÎšÎ¡ÎŸÎ¥Î£Î— fallback
    if "Î£Î¥Î“ÎšÎ¡ÎŸÎ¥Î£Î—" not in renamed.columns:
        if "Î£Î¥Î“ÎšÎ¡ÎŸÎ¥Î£Î•Î™Î£" in renamed.columns:
            renamed = renamed.rename(columns={"Î£Î¥Î“ÎšÎ¡ÎŸÎ¥Î£Î•Î™Î£": "Î£Î¥Î“ÎšÎ¡ÎŸÎ¥Î£Î—"})
        else:
            renamed["Î£Î¥Î“ÎšÎ¡ÎŸÎ¥Î£Î—"] = ""
    return renamed, mapping

# ---------------------------
# Name canonicalization helpers
# ---------------------------

def _strip_diacritics(s: str) -> str:
    nfkd = unicodedata.normalize("NFD", s)
    return "".join(ch for ch in nfkd if not unicodedata.combining(ch))

def _canon_name(s: str) -> str:
    s = (str(s) if s is not None else "").strip()
    s = s.strip("[]'\" ")
    s = re.sub(r"\s+", " ", s)
    s = _strip_diacritics(s).upper()
    return s

_SPLIT_RE = re.compile(r"\s*(?:,|;|/|\||\band\b|\bÎºÎ±Î¹\b|\+|\n)\s*", flags=re.IGNORECASE)

# ---------------------------
# Friends parsing & broken pairs
# ---------------------------

def _parse_friends(cell):
    raw = str(cell) if cell is not None else ""
    raw = raw.strip()
    if not raw:
        return []
    if raw.startswith("[") and raw.endswith("]"):
        try:
            val = ast.literal_eval(raw)
            if isinstance(val, (list, tuple)):
                return [_canon_name(x) for x in val if str(x).strip()]
        except Exception:
            pass
        raw2 = raw.strip("[]")
        parts = re.split(r"[;,]", raw2)
        return [_canon_name(p) for p in parts if _canon_name(p)]
    parts = [p for p in _SPLIT_RE.split(raw) if p]
    return [_canon_name(p) for p in parts if _canon_name(p)]


def list_broken_mutual_pairs(df: pd.DataFrame) -> pd.DataFrame:
    """Î•Ï€Î¹ÏƒÏ„ÏÎ­Ï†ÎµÎ¹ DataFrame Î¼Îµ ÎºÎ¬Î¸Îµ **ÏƒÏ€Î±ÏƒÎ¼Î­Î½Î· Ï€Î»Î®ÏÏ‰Ï‚ Î±Î¼Î¿Î¹Î²Î±Î¯Î± Î´Ï…Î¬Î´Î±** (A/B + Ï„Î¼Î®Î¼Î±Ï„Î±)."""
    fcol = None
    for candidate in ["Î¦Î™Î›ÎŸÎ™","Î¦Î™Î›Î™Î‘","Î¦Î™Î›ÎŸÎ£"]:
        if candidate in df.columns:
            fcol = candidate
            break
    if fcol is None or "ÎŸÎÎŸÎœÎ‘" not in df.columns or "Î¤ÎœÎ—ÎœÎ‘" not in df.columns:
        return pd.DataFrame(columns=["A","A_Î¤ÎœÎ—ÎœÎ‘","B","B_Î¤ÎœÎ—ÎœÎ‘"])

    df = df.copy()
    df["__CAN_NAME__"] = df["ÎŸÎÎŸÎœÎ‘"].map(_canon_name)
    name_to_original = dict(zip(df["__CAN_NAME__"], df["ÎŸÎÎŸÎœÎ‘"].astype(str)))
    class_by_name = dict(zip(df["__CAN_NAME__"], df["Î¤ÎœÎ—ÎœÎ‘"].astype(str).str.strip()))

    token_index = {}
    for full in df["__CAN_NAME__"]:
        tokens = [t for t in re.split(r"\s+", full) if t]
        for t in tokens:
            token_index.setdefault(t, set()).add(full)

    def resolve_friend(s: str):
        s = _canon_name(s)
        if not s:
            return None
        if s in name_to_original:
            return s
        toks = [t for t in re.split(r"\s+", s) if t]
        if not toks:
            return None
        if len(toks) >= 2:
            sets = [token_index.get(t, set()) for t in toks]
            inter = set.intersection(*sets) if sets else set()
            if len(inter) == 1:
                return next(iter(inter))
            union = set().union(*sets)
            if len(union) == 1:
                return next(iter(union))
            return None
        else:
            group = token_index.get(toks[0], set())
            return next(iter(group)) if len(group) == 1 else None

    friends_by_name = {}
    for _, row in df.iterrows():
        me = row["__CAN_NAME__"]
        flist_raw = _parse_friends(row[fcol])
        resolved = set()
        for fr in flist_raw:
            r = resolve_friend(fr)
            if r and r != me:
                resolved.add(r)
        friends_by_name[me] = resolved

    mutual_pairs = set()
    for a, flist in friends_by_name.items():
        for b in flist:
            if b in friends_by_name and a in friends_by_name[b]:
                mutual_pairs.add(tuple(sorted([a,b])))

    rows = []
    for a, b in sorted(mutual_pairs):
        ta = class_by_name.get(a, "")
        tb = class_by_name.get(b, "")
        if ta and tb and ta != tb:
            rows.append({
                "A": name_to_original.get(a, a), "A_Î¤ÎœÎ—ÎœÎ‘": ta,
                "B": name_to_original.get(b, b), "B_Î¤ÎœÎ—ÎœÎ‘": tb,
            })
    return pd.DataFrame(rows)

# ---------------------------
# Broken friendships per student (counts + names)
# ---------------------------

def compute_broken_friend_names_per_student(df: pd.DataFrame):
    """Return (counts_series, names_series) per student for ÏƒÏ€Î±ÏƒÎ¼Î­Î½ÎµÏ‚ Ï€Î»Î®ÏÏ‰Ï‚ Î±Î¼Î¿Î¹Î²Î±Î¯ÎµÏ‚ Î´Ï…Î¬Î´ÎµÏ‚."""
    if not {"ÎŸÎÎŸÎœÎ‘", "Î¤ÎœÎ—ÎœÎ‘"}.issubset(df.columns):
        return pd.Series([0]*len(df), index=df.index), pd.Series([""]*len(df), index=df.index)

    df_local = df.copy()
    df_local["__CAN_NAME__"] = df_local["ÎŸÎÎŸÎœÎ‘"].map(_canon_name)
    canon_to_display = dict(zip(df_local["__CAN_NAME__"], df_local["ÎŸÎÎŸÎœÎ‘"].astype(str)))

    broken_df = list_broken_mutual_pairs(df_local)
    broken_map = {cn: [] for cn in df_local["__CAN_NAME__"]}

    for _, row in broken_df.iterrows():
        a = _canon_name(row.get("A", "")) if "A" in row else ""
        b = _canon_name(row.get("B", "")) if "B" in row else ""
        if a and b:
            broken_map.setdefault(a, []).append(canon_to_display.get(b, row.get("B", "")))
            broken_map.setdefault(b, []).append(canon_to_display.get(a, row.get("A", "")))

    counts, names = [], []
    for cn in df_local["__CAN_NAME__"]:
        lst = broken_map.get(cn, []) or []
        counts.append(len(lst))
        names.append(", ".join(lst))
    return pd.Series(counts, index=df.index), pd.Series(names, index=df.index)

# ---------------------------
# Conflicts per student (NO pairs)
# ---------------------------

def _parse_conflict_targets(cell):
    raw = str(cell) if cell is not None else ""
    raw = raw.strip()
    if not raw:
        return []
    if raw.startswith("[") and raw.endswith("]"):
        try:
            val = ast.literal_eval(raw)
            if isinstance(val, (list, tuple)):
                return [_canon_name(x) for x in val if str(x).strip()]
        except Exception:
            pass
        raw2 = raw.strip("[]")
        parts = re.split(r"[;,]", raw2)
        return [_canon_name(p) for p in parts if _canon_name(p)]
    parts = [p for p in _SPLIT_RE.split(raw) if p]
    return [_canon_name(p) for p in parts if _canon_name(p)]


def _build_name_resolution(df: pd.DataFrame):
    df = df.copy()
    df["__CAN_NAME__"] = df["ÎŸÎÎŸÎœÎ‘"].map(_canon_name)
    name_to_original = dict(zip(df["__CAN_NAME__"], df["ÎŸÎÎŸÎœÎ‘"].astype(str)))
    class_by_name = dict(zip(df["__CAN_NAME__"], df["Î¤ÎœÎ—ÎœÎ‘"].astype(str).str.strip()))
    token_index = {}
    for full in df["__CAN_NAME__"]:
        tokens = [t for t in re.split(r"\s+", full) if t]
        for t in tokens:
            token_index.setdefault(t, set()).add(full)
    def resolve_name(s: str):
        s = _canon_name(s)
        if not s:
            return None
        if s in name_to_original:
            return s
        toks = [t for t in re.split(r"\s+", s) if t]
        if not toks:
            return None
        if len(toks) >= 2:
            sets = [token_index.get(t, set()) for t in toks]
            inter = set.intersection(*sets) if sets else set()
            if len(inter) == 1:
                return next(iter(inter))
            union = set().union(*sets)
            if len(union) == 1:
                return next(iter(union))
            return None
        else:
            group = token_index.get(toks[0], set())
            return next(iter(group)) if len(group) == 1 else None
    return name_to_original, class_by_name, resolve_name


def compute_conflict_counts_and_names(df: pd.DataFrame):
    """
    Return (counts_series, names_series) per student.
    - counts_series: Ï€ÏŒÏƒÎ¿Î¹ Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Î´Î·Î»Ï‰Î¼Î­Î½Î¿Ï…Ï‚ Î²ÏÎ¯ÏƒÎºÎ¿Î½Ï„Î±Î¹ ÏƒÏ„Î·Î½ **Î¯Î´Î¹Î± Ï„Î¬Î¾Î·** (Î¼Î¿Î½ÏŒÏ€Î»ÎµÏ…ÏÎ· Î´Î®Î»Ï‰ÏƒÎ· Î±ÏÎºÎµÎ¯).
    - names_series: Î¿Î½ÏŒÎ¼Î±Ï„Î± Î±Ï…Ï„ÏÎ½ Ï„Ï‰Î½ Î¼Î±Î¸Î·Ï„ÏÎ½ (comma-separated).
    """
    required = {"ÎŸÎÎŸÎœÎ‘", "Î¤ÎœÎ—ÎœÎ‘", "Î£Î¥Î“ÎšÎ¡ÎŸÎ¥Î£Î—"}
    if not required.issubset(set(df.columns)):
        return pd.Series([0]*len(df), index=df.index), pd.Series([""]*len(df), index=df.index)

    name_to_original, class_by_name, resolve_name = _build_name_resolution(df)

    canon_names = df["ÎŸÎÎŸÎœÎ‘"].map(_canon_name)
    counts = [0]*len(df)
    names = [""]*len(df)

    index_by_canon = {cn: i for i, cn in enumerate(canon_names)}

    for i, row in df.iterrows():
        me = _canon_name(row["ÎŸÎÎŸÎœÎ‘"])
        my_class = class_by_name.get(me, "")
        targets = _parse_conflict_targets(row["Î£Î¥Î“ÎšÎ¡ÎŸÎ¥Î£Î—"])
        same_class_names = []
        for t in targets:
            r = resolve_name(t)
            if r and r != me:
                if class_by_name.get(r, None) == my_class and my_class:
                    same_class_names.append(name_to_original.get(r, r))
        counts[index_by_canon.get(me, i)] = len(same_class_names)
        names[index_by_canon.get(me, i)] = ", ".join(same_class_names)

    return pd.Series(counts, index=df.index), pd.Series(names, index=df.index)

# ---------------------------
# Stats generator
# ---------------------------

def generate_stats(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()
    if "Î¤ÎœÎ—ÎœÎ‘" in df:
        df["Î¤ÎœÎ—ÎœÎ‘"] = df["Î¤ÎœÎ—ÎœÎ‘"].apply(lambda v: v.strip() if isinstance(v, str) else v)
    if "Î¦Î¥Î›ÎŸ" in df:
        df["Î¦Î¥Î›ÎŸ"] = df["Î¦Î¥Î›ÎŸ"].fillna("").astype(str).str.strip().str.upper()
    for col in ["Î Î‘Î™Î”Î™_Î•ÎšÎ Î‘Î™Î”Î•Î¥Î¤Î™ÎšÎŸÎ¥","Î–Î©Î—Î¡ÎŸÎ£","Î™Î”Î™Î‘Î™Î¤Î•Î¡ÎŸÎ¤Î—Î¤Î‘","ÎšÎ‘Î›Î—_Î“ÎÎ©Î£Î—_Î•Î›Î›Î—ÎÎ™ÎšÎ©Î"]:
        if col in df:
            s = df[col]
            if s.dtype == object:
                s = s.fillna("").astype(str).str.strip().str.upper().replace({
                    "ÎÎ‘Î™":"Î","NAI":"Î","YES":"Î","Y":"Î",
                    "ÎŸÎ§Î™":"ÎŸ","OXI":"ÎŸ","NO":"ÎŸ","N":"ÎŸ","": "ÎŸ"
                })
                df[col] = s.where(s.isin(["Î","ÎŸ"]), other="ÎŸ")

    boys = df[df.get("Î¦Î¥Î›ÎŸ", "").eq("Î‘")].groupby("Î¤ÎœÎ—ÎœÎ‘").size() if "Î¦Î¥Î›ÎŸ" in df else pd.Series(dtype=int)
    girls = df[df.get("Î¦Î¥Î›ÎŸ", "").eq("Îš")].groupby("Î¤ÎœÎ—ÎœÎ‘").size() if "Î¦Î¥Î›ÎŸ" in df else pd.Series(dtype=int)
    educators = df[df.get("Î Î‘Î™Î”Î™_Î•ÎšÎ Î‘Î™Î”Î•Î¥Î¤Î™ÎšÎŸÎ¥", "").eq("Î")].groupby("Î¤ÎœÎ—ÎœÎ‘").size() if "Î Î‘Î™Î”Î™_Î•ÎšÎ Î‘Î™Î”Î•Î¥Î¤Î™ÎšÎŸÎ¥" in df else pd.Series(dtype=int)
    energetic = df[df.get("Î–Î©Î—Î¡ÎŸÎ£", "").eq("Î")].groupby("Î¤ÎœÎ—ÎœÎ‘").size() if "Î–Î©Î—Î¡ÎŸÎ£" in df else pd.Series(dtype=int)
    special = df[df.get("Î™Î”Î™Î‘Î™Î¤Î•Î¡ÎŸÎ¤Î—Î¤Î‘", "").eq("Î")].groupby("Î¤ÎœÎ—ÎœÎ‘").size() if "Î™Î”Î™Î‘Î™Î¤Î•Î¡ÎŸÎ¤Î—Î¤Î‘" in df else pd.Series(dtype=int)
    greek = df[df.get("ÎšÎ‘Î›Î—_Î“ÎÎ©Î£Î—_Î•Î›Î›Î—ÎÎ™ÎšÎ©Î", "").eq("Î")].groupby("Î¤ÎœÎ—ÎœÎ‘").size() if "ÎšÎ‘Î›Î—_Î“ÎÎ©Î£Î—_Î•Î›Î›Î—ÎÎ™ÎšÎ©Î" in df else pd.Series(dtype=int)
    total = df.groupby("Î¤ÎœÎ—ÎœÎ‘").size() if "Î¤ÎœÎ—ÎœÎ‘" in df else pd.Series(dtype=int)

    # Broken friendships per class
    try:
        pairs = list_broken_mutual_pairs(df)
        if pairs.empty:
            broken = pd.Series({tmima: 0 for tmima in df["Î¤ÎœÎ—ÎœÎ‘"].dropna().astype(str).str.strip().unique()})
        else:
            counts = {}
            for _, row in pairs.iterrows():
                a_c = str(row["A_Î¤ÎœÎ—ÎœÎ‘"]).strip(); b_c = str(row["B_Î¤ÎœÎ—ÎœÎ‘"]).strip()
                counts[a_c] = counts.get(a_c, 0) + 1
                counts[b_c] = counts.get(b_c, 0) + 1
            broken = pd.Series(counts).astype(int)
    except Exception:
        broken = pd.Series(dtype=int)

    # Conflicts per class = sum of per-student counts (no pairs)
    try:
        conf_counts, _conf_names = compute_conflict_counts_and_names(df)
        if "Î¤ÎœÎ—ÎœÎ‘" in df:
            cls = df["Î¤ÎœÎ—ÎœÎ‘"].astype(str).str.strip()
            conflict_by_class = conf_counts.groupby(cls).sum().astype(int)
        else:
            conflict_by_class = pd.Series(dtype=int)
    except Exception:
        conflict_by_class = pd.Series(dtype=int)

    stats = pd.DataFrame({
        "Î‘Î“ÎŸÎ¡Î™Î‘": boys,
        "ÎšÎŸÎ¡Î™Î¤Î£Î™Î‘": girls,
        "Î Î‘Î™Î”Î™_Î•ÎšÎ Î‘Î™Î”Î•Î¥Î¤Î™ÎšÎŸÎ¥": educators,
        "Î–Î©Î—Î¡ÎŸÎ™": energetic,
        "Î™Î”Î™Î‘Î™Î¤Î•Î¡ÎŸÎ¤Î—Î¤Î‘": special,
        "Î“ÎÎ©Î£Î— Î•Î›Î›Î—ÎÎ™ÎšÎ©Î": greek,
        "Î£Î¥Î“ÎšÎ¡ÎŸÎ¥Î£Î—": conflict_by_class,
        "Î£Î Î‘Î£ÎœÎ•ÎÎ— Î¦Î™Î›Î™Î‘": broken,
        "Î£Î¥ÎÎŸÎ›ÎŸ ÎœÎ‘Î˜Î—Î¤Î©Î": total,
    }).fillna(0).astype(int)

    if hasattr(stats.index, "str"):
        stats = stats.loc[stats.index.str.lower() != "nan"]
    try:
        stats = stats.sort_index(key=lambda x: x.str.extract(r"(\d+)")[0].astype(float))
    except Exception:
        stats = stats.sort_index()
    return stats

# ---------------------------
# Export helpers
# ---------------------------

def export_stats_to_excel(stats_df: pd.DataFrame) -> BytesIO:
    output = BytesIO()
    with pd.ExcelWriter(output, engine="xlsxwriter") as writer:
        stats_df.to_excel(writer, index=True, sheet_name="Î£Ï„Î±Ï„Î¹ÏƒÏ„Î¹ÎºÎ¬", index_label="Î¤ÎœÎ—ÎœÎ‘")
        wb = writer.book
        ws = writer.sheets["Î£Ï„Î±Ï„Î¹ÏƒÏ„Î¹ÎºÎ¬"]
        header_fmt = wb.add_format({"bold": True, "valign":"vcenter", "text_wrap": True, "border":1})
        for col_idx, value in enumerate(["Î¤ÎœÎ—ÎœÎ‘"] + list(stats_df.columns)):
            ws.write(0, col_idx, value, header_fmt)
        for i in range(0, len(stats_df.columns)+1):
            ws.set_column(i, i, 18)
    output.seek(0)
    return output


def sanitize_sheet_name(s: str) -> str:
    s = str(s or "")
    s = re.sub(r'[:\\/?*\\[\\]]', ' ', s)
    return s[:31] if s else "SHEET"

# ---------------------------
# Upload (with resettable key)
# ---------------------------

st.markdown("### ğŸ“¥ Î•Î¹ÏƒÎ±Î³Ï‰Î³Î® Î‘ÏÏ‡ÎµÎ¯Î¿Ï… Excel")
uploaded = st.file_uploader(
    "Î•Ï€Î¯Î»ÎµÎ¾Îµ **Excel** Î¼Îµ Î­Î½Î± Î® Ï€ÎµÏÎ¹ÏƒÏƒÏŒÏ„ÎµÏÎ± sheets (ÏƒÎµÎ½Î¬ÏÎ¹Î±)",
    type=["xlsx","xls"],
    key=f"uploader_{st.session_state['uploader_key']}"
)

if not uploaded:
    st.info("â• Î‘Î½Î­Î²Î±ÏƒÎµ Î­Î½Î± Excel Î³Î¹Î± Î½Î± ÏƒÏ…Î½ÎµÏ‡Î¯ÏƒÎµÎ¹Ï‚.")
    st.stop()

try:
    xl = pd.ExcelFile(uploaded)
    st.success(f"âœ… Î•Ï€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î± Î±ÏÏ‡ÎµÎ¯Î¿Ï…: **{uploaded.name}** â€” Î’ÏÎ­Î¸Î·ÎºÎ±Î½ {len(xl.sheet_names)} sheet(s).")
except Exception as e:
    st.error(f"âŒ Î£Ï†Î¬Î»Î¼Î± Î±Î½Î¬Î³Î½Ï‰ÏƒÎ·Ï‚: {e}")
    st.stop()

# ---------------------------
# Tabs (NO conflict pairs tab)
# ---------------------------

tab_stats, tab_broken, tab_mass = st.tabs([
    "ğŸ“Š Î£Ï„Î±Ï„Î¹ÏƒÏ„Î¹ÎºÎ¬ (1 sheet)",
    "ğŸ§© Î£Ï€Î±ÏƒÎ¼Î­Î½ÎµÏ‚ Î±Î¼Î¿Î¹Î²Î±Î¯ÎµÏ‚ (ÏŒÎ»Î± Ï„Î± sheets) â€” ÎˆÎ¾Î¿Î´Î¿Ï‚: Î Î»Î®ÏÎµÏ‚ Î±Î½Ï„Î¯Î³ÏÎ±Ï†Î¿ + Î£ÏÎ½Î¿ÏˆÎ·",
    "ğŸ“¦ ÎœÎ±Î¶Î¹ÎºÎ­Ï‚ Î±Î½Î±Ï†Î¿ÏÎ­Ï‚",
])

with tab_stats:
    st.subheader("ğŸ“Š Î¥Ï€Î¿Î»Î¿Î³Î¹ÏƒÎ¼ÏŒÏ‚ Î£Ï„Î±Ï„Î¹ÏƒÏ„Î¹ÎºÏÎ½ Î³Î¹Î± Î•Ï€Î¹Î»ÎµÎ³Î¼Î­Î½Î¿ Sheet")
    sheet = st.selectbox("Î”Î¹Î¬Î»ÎµÎ¾Îµ sheet", options=xl.sheet_names, index=0)
    df_raw = xl.parse(sheet_name=sheet)
    df_norm, ren_map = auto_rename_columns(df_raw)

    # âœ… ÎœÎµÏ„ÏÎ·Ï„Î®Ï‚ Î£Î¥Î“ÎšÎ¡ÎŸÎ¥Î£Î— & Î¿Î½ÏŒÎ¼Î±Ï„Î± (Ï‡Ï‰ÏÎ¯Ï‚ Î¶ÎµÏÎ³Î· Aâ€“B)
    try:
        conflict_counts, conflict_names = compute_conflict_counts_and_names(df_norm)
        df_with = df_norm.copy()
        df_with["Î£Î¥Î“ÎšÎ¡ÎŸÎ¥Î£Î—"] = conflict_counts.astype(int)
        df_with["Î£Î¥Î“ÎšÎ¡ÎŸÎ¥Î£Î—_ÎŸÎÎŸÎœÎ‘"] = conflict_names
        # ğŸ§© Î£Ï€Î±ÏƒÎ¼Î­Î½ÎµÏ‚ Î±Î¼Î¿Î¹Î²Î±Î¯ÎµÏ‚ Î±Î½Î¬ Î¼Î±Î¸Î·Ï„Î® (Î¼ÎµÏ„ÏÎ·Ï„Î®Ï‚ + Î¿Î½ÏŒÎ¼Î±Ï„Î±)
        try:
            broken_counts_ps, broken_names_ps = compute_broken_friend_names_per_student(df_norm)
            df_with["Î£Î Î‘Î£ÎœÎ•ÎÎ—_Î¦Î™Î›Î™Î‘"] = broken_counts_ps.astype(int)
            df_with["Î£Î Î‘Î£ÎœÎ•ÎÎ—_Î¦Î™Î›Î™Î‘_ÎŸÎÎŸÎœÎ‘"] = broken_names_ps
        except Exception:
            pass
    except Exception:
        df_with = df_norm

    missing = [c for c in REQUIRED_COLS if c not in df_norm.columns]
    with st.expander("ğŸ” Î”Î¹Î¬Î³Î½Ï‰ÏƒÎ·/ÎœÎµÏ„Î¿Î½Î¿Î¼Î±ÏƒÎ¯ÎµÏ‚", expanded=False):
        st.write("Î‘Î½Î±Î³Î½Ï‰ÏÎ¹ÏƒÎ¼Î­Î½ÎµÏ‚ ÏƒÏ„Î®Î»ÎµÏ‚:", list(df_norm.columns))
        if ren_map:
            st.write("Î‘Ï…Ï„ÏŒÎ¼Î±Ï„ÎµÏ‚ Î¼ÎµÏ„Î¿Î½Î¿Î¼Î±ÏƒÎ¯ÎµÏ‚:", ren_map)
        if missing:
            st.error("âŒ Î›ÎµÎ¯Ï€Î¿Ï…Î½ Ï…Ï€Î¿Ï‡ÏÎµÏ‰Ï„Î¹ÎºÎ­Ï‚ ÏƒÏ„Î®Î»ÎµÏ‚: " + ", ".join(missing))

    if not missing:
        with st.expander("ğŸ‘ï¸ Î Î¯Î½Î±ÎºÎ±Ï‚ Î¼Î±Î¸Î·Ï„ÏÎ½ (Î¼Îµ Î£Î¥Î“ÎšÎ¡ÎŸÎ¥Î£Î— & Î¿Î½ÏŒÎ¼Î±Ï„Î±)", expanded=False):
            st.dataframe(df_with, use_container_width=True)
            # Î›Î®ÏˆÎ· Ï‰Ï‚ Excel
            bio_conf = BytesIO()
            with pd.ExcelWriter(bio_conf, engine="xlsxwriter") as writer:
                df_with.to_excel(writer, index=False, sheet_name="ÎœÎ±Î¸Î·Ï„Î­Ï‚_Î£ÏÎ³ÎºÏÎ¿Ï…ÏƒÎ·")
            bio_conf.seek(0)
            st.download_button(
                "â¬‡ï¸ ÎšÎ±Ï„Î­Î²Î±ÏƒÎµ Ï€Î¯Î½Î±ÎºÎ± Î¼Î±Î¸Î·Ï„ÏÎ½ (Î¼Îµ Î£Î¥Î“ÎšÎ¡ÎŸÎ¥Î£Î— & Î¿Î½ÏŒÎ¼Î±Ï„Î±)",
                data=bio_conf.getvalue(),
                file_name=f"students_conflicts_{sanitize_sheet_name(sheet)}.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
            )

        # ğŸ§® Î£Ï„Î±Ï„Î¹ÏƒÏ„Î¹ÎºÎ¬ Î±Î½Î¬ Ï„Î¼Î®Î¼Î±
        stats_df = generate_stats(df_norm)
        # Î”Î¹Î±ÏƒÏ†Î¬Î»Î¹ÏƒÎ· ÏÏ€Î±ÏÎ¾Î·Ï‚ ÏƒÏ„Î®Î»Î·Ï‚ "Î£Î¥Î“ÎšÎ¡ÎŸÎ¥Î£Î—" ÏƒÏ„Î± ÏƒÏ„Î±Ï„Î¹ÏƒÏ„Î¹ÎºÎ¬
        if "Î£Î¥Î“ÎšÎ¡ÎŸÎ¥Î£Î—" not in stats_df.columns:
            try:
                conf_counts, _conf_names = compute_conflict_counts_and_names(df_norm)
                if "Î¤ÎœÎ—ÎœÎ‘" in df_norm:
                    cls = df_norm["Î¤ÎœÎ—ÎœÎ‘"].astype(str).str.strip()
                    conflict_by_class = conf_counts.groupby(cls).sum().astype(int)
                else:
                    conflict_by_class = pd.Series(dtype=int)
                stats_df["Î£Î¥Î“ÎšÎ¡ÎŸÎ¥Î£Î—"] = [int(conflict_by_class.get(str(idx).strip(), 0)) for idx in stats_df.index]
                cols = list(stats_df.columns)
                if "Î£Î Î‘Î£ÎœÎ•ÎÎ— Î¦Î™Î›Î™Î‘" in cols:
                    cols.insert(cols.index("Î£Î Î‘Î£ÎœÎ•ÎÎ— Î¦Î™Î›Î™Î‘"), cols.pop(cols.index("Î£Î¥Î“ÎšÎ¡ÎŸÎ¥Î£Î—")))
                    stats_df = stats_df[cols]
            except Exception:
                pass

        st.dataframe(stats_df, use_container_width=True)
        st.download_button(
            "ğŸ’¾ Î›Î®ÏˆÎ· Î Î¯Î½Î±ÎºÎ± Î£Ï„Î±Ï„Î¹ÏƒÏ„Î¹ÎºÏÎ½ (Excel)",
            data=export_stats_to_excel(stats_df).getvalue(),
            file_name=f"statistika_{sanitize_sheet_name(sheet)}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            type="primary"
        )
    else:
        st.info("Î£Ï…Î¼Ï€Î»Î®ÏÏ‰ÏƒÎµ/Î´Î¹ÏŒÏÎ¸Ï‰ÏƒÎµ Ï„Î¹Ï‚ ÏƒÏ„Î®Î»ÎµÏ‚ Ï€Î¿Ï… Î»ÎµÎ¯Ï€Î¿Ï…Î½ ÏƒÏ„Î¿ Excel ÎºÎ±Î¹ Î¾Î±Î½Î±Ï†ÏŒÏÏ„Ï‰ÏƒÎ­ Ï„Î¿.")

with tab_broken:
    st.subheader("ğŸ§© Î‘Î½Î±Ï†Î¿ÏÎ¬ Î£Ï€Î±ÏƒÎ¼Î­Î½Ï‰Î½ Î Î»Î®ÏÏ‰Ï‚ Î‘Î¼Î¿Î¹Î²Î±Î¯Ï‰Î½ Î”Ï…Î¬Î´Ï‰Î½ (ÏŒÎ»Î± Ï„Î± sheets)")
    summary_rows = []
    for sheet in xl.sheet_names:
        df_raw = xl.parse(sheet_name=sheet)
        df_norm, _ = auto_rename_columns(df_raw)
        broken_df = list_broken_mutual_pairs(df_norm)
        summary_rows.append({"Î£ÎµÎ½Î¬ÏÎ¹Î¿ (sheet)": sheet, "Î£Ï€Î±ÏƒÎ¼Î­Î½ÎµÏ‚ Î”Ï…Î¬Î´ÎµÏ‚": int(len(broken_df))})
    summary = pd.DataFrame(summary_rows).sort_values("Î£ÎµÎ½Î¬ÏÎ¹Î¿ (sheet)")
    st.dataframe(summary, use_container_width=True)

    # Build full report: copy originals + *_BROKEN + Î£ÏÎ½Î¿ÏˆÎ·
    def build_broken_report(xl_file: pd.ExcelFile) -> BytesIO:
        bio = BytesIO()
        rows = []
        with pd.ExcelWriter(bio, engine="xlsxwriter") as writer:
            for sheet in xl_file.sheet_names:
                df_raw = xl_file.parse(sheet_name=sheet)
                df_raw.to_excel(writer, index=False, sheet_name=sanitize_sheet_name(sheet))
            for sheet in xl_file.sheet_names:
                df_raw = xl_file.parse(sheet_name=sheet)
                df_norm, _ = auto_rename_columns(df_raw)
                broken_df = list_broken_mutual_pairs(df_norm)
                rows.append({"Î£ÎµÎ½Î¬ÏÎ¹Î¿ (sheet)": sheet, "Î£Ï€Î±ÏƒÎ¼Î­Î½ÎµÏ‚ Î”Ï…Î¬Î´ÎµÏ‚": int(len(broken_df))})
                out_name = sanitize_sheet_name(f"{sheet}_BROKEN")
                if broken_df.empty:
                    pd.DataFrame({"info": ["â€” ÎºÎ±Î¼Î¯Î± ÏƒÏ€Î±ÏƒÎ¼Î­Î½Î· â€”"]}).to_excel(writer, index=False, sheet_name=out_name)
                else:
                    broken_df.to_excel(writer, index=False, sheet_name=out_name)
            pd.DataFrame(rows).sort_values("Î£ÎµÎ½Î¬ÏÎ¹Î¿ (sheet)").to_excel(writer, index=False, sheet_name="Î£ÏÎ½Î¿ÏˆÎ·")
        bio.seek(0)
        return bio

    st.download_button(
        "â¬‡ï¸ ÎšÎ±Ï„Î­Î²Î±ÏƒÎµ Î±Î½Î±Ï†Î¿ÏÎ¬ (Î Î»Î®ÏÎµÏ‚ Î±Î½Ï„Î¯Î³ÏÎ±Ï†Î¿ + ÏƒÏ€Î±ÏƒÎ¼Î­Î½ÎµÏ‚ + ÏƒÏÎ½Î¿ÏˆÎ·)",
        data=build_broken_report(xl).getvalue(),
        file_name=f"broken_friends_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
    )

    with st.expander("ğŸ” Î ÏÎ¿Î²Î¿Î»Î® Î±Î½Î±Î»Ï…Ï„Î¹ÎºÏÎ½ Î¶ÎµÏ…Î³ÏÎ½ & Î´Î¹Î¬Î³Î½Ï‰ÏƒÎ· Î±Î½Î¬ sheet"):
        for sheet in xl.sheet_names:
            df_raw = xl.parse(sheet_name=sheet)
            df_norm, _ = auto_rename_columns(df_raw)
            broken_df = list_broken_mutual_pairs(df_norm)
            # Î”Î¹Î¬Î³Î½Ï‰ÏƒÎ· Î±Î½Ï„Î¹ÏƒÏ„Î¿Î¯Ï‡Î¹ÏƒÎ·Ï‚ Î¿Î½Î¿Î¼Î¬Ï„Ï‰Î½
            # (Ï€ÏÎ¿Î±Î¹ÏÎµÏ„Î¹ÎºÎ¬ Î¼Ï€Î¿ÏÎµÎ¯ Î½Î± Ï€ÏÎ¿ÏƒÏ„ÎµÎ¸ÎµÎ¯ Î»ÎµÏ€Ï„Î¿Î¼ÎµÏÎ®Ï‚ Î´Î¹Î¬Î³Î½Ï‰ÏƒÎ· ÏŒÏ€Ï‰Ï‚ ÏƒÏ„Î¿ app3)
            st.markdown(f"**{sheet}**")
            if broken_df.empty:
                st.info("â€” ÎšÎ±Î¼Î¯Î± ÏƒÏ€Î±ÏƒÎ¼Î­Î½Î· Ï€Î»Î®ÏÏ‰Ï‚ Î±Î¼Î¿Î¹Î²Î±Î¯Î± Î´Ï…Î¬Î´Î± â€”")
            else:
                st.dataframe(broken_df, use_container_width=True)

# ===========================
# ğŸ“¦ Mass report (all sheets): broken friendships + conflicts (per-student only)
# ===========================

with tab_mass:
    st.subheader("ğŸ“¦ ÎœÎ±Î¶Î¹ÎºÎ­Ï‚ Î±Î½Î±Ï†Î¿ÏÎ­Ï‚ â€” Î£Ï€Î±ÏƒÎ¼Î­Î½ÎµÏ‚ Ï†Î¹Î»Î¯ÎµÏ‚ & Î£Ï…Î³ÎºÏÎ¿ÏÏƒÎµÎ¹Ï‚ (Ï‡Ï‰ÏÎ¯Ï‚ Î¶ÎµÏÎ³Î· ÏƒÏÎ³ÎºÏÎ¿Ï…ÏƒÎ·Ï‚)")

    def build_mass_broken_and_conflicts_report(xl_file: pd.ExcelFile) -> BytesIO:
        bio = BytesIO()
        summary_rows = []
        with pd.ExcelWriter(bio, engine="xlsxwriter") as writer:
            for idx, sheet in enumerate(xl_file.sheet_names, start=1):
                df_raw = xl_file.parse(sheet_name=sheet)
                df_norm, _ = auto_rename_columns(df_raw)

                broken_pairs = list_broken_mutual_pairs(df_norm)
                conf_counts, conf_names = compute_conflict_counts_and_names(df_norm)

                broken_counts_ps, broken_names_ps = compute_broken_friend_names_per_student(df_norm)
                df_ps_broken = pd.DataFrame({
                    "ÎŸÎÎŸÎœÎ‘": df_norm.get("ÎŸÎÎŸÎœÎ‘", pd.Series(dtype=str)),
                    "Î¤ÎœÎ—ÎœÎ‘": df_norm.get("Î¤ÎœÎ—ÎœÎ‘", pd.Series(dtype=str)),
                    "Î£Î Î‘Î£ÎœÎ•ÎÎ—_Î¦Î™Î›Î™Î‘": broken_counts_ps.astype(int),
                    "Î£Î Î‘Î£ÎœÎ•ÎÎ—_Î¦Î™Î›Î™Î‘_ÎŸÎÎŸÎœÎ‘": broken_names_ps,
                })
                df_ps_conf = pd.DataFrame({
                    "ÎŸÎÎŸÎœÎ‘": df_norm.get("ÎŸÎÎŸÎœÎ‘", pd.Series(dtype=str)),
                    "Î¤ÎœÎ—ÎœÎ‘": df_norm.get("Î¤ÎœÎ—ÎœÎ‘", pd.Series(dtype=str)),
                    "Î£Î¥Î“ÎšÎ¡ÎŸÎ¥Î£Î—": conf_counts.astype(int),
                    "Î£Î¥Î“ÎšÎ¡ÎŸÎ¥Î£Î—_ÎŸÎÎŸÎœÎ‘": conf_names,
                })

                bp_name  = f"S{idx}_BP"   # broken pairs
                bps_name = f"S{idx}_BPS"  # broken per student
                cps_name = f"S{idx}_CPS"  # conflicts per student

                (broken_pairs if not broken_pairs.empty else pd.DataFrame({"info":["â€” ÎºÎ±Î¼Î¯Î± â€”"]})).to_excel(writer, index=False, sheet_name=bp_name)
                df_ps_broken.to_excel(writer, index=False, sheet_name=bps_name)
                df_ps_conf.to_excel(writer, index=False, sheet_name=cps_name)

                summary_rows.append({
                    "Index": idx,
                    "Original sheet name": sheet,
                    "S-code": f"S{idx}",
                    "Broken Pairs (rows)": int(len(broken_pairs)),
                    "Students with â‰¥1 Broken Friendship": int((broken_counts_ps.fillna(0) > 0).sum()),
                    "Students with â‰¥1 Conflict in Same Class": int((conf_counts.fillna(0) > 0).sum()),
                })

            pd.DataFrame(summary_rows).to_excel(writer, index=False, sheet_name="SUMMARY")
        bio.seek(0)
        return bio

    # Î–Ï‰Î½Ï„Î±Î½Î® ÏƒÏÎ½Î¿ÏˆÎ·
    summary_rows = []
    for sheet in xl.sheet_names:
        df_raw = xl.parse(sheet_name=sheet)
        df_norm, _ = auto_rename_columns(df_raw)
        bp = list_broken_mutual_pairs(df_norm)
        bc_ps, _ = compute_broken_friend_names_per_student(df_norm)
        conf_counts, _ = compute_conflict_counts_and_names(df_norm)
        summary_rows.append({
            "Î£ÎµÎ½Î¬ÏÎ¹Î¿ (sheet)": sheet,
            "Î£Ï€Î±ÏƒÎ¼Î­Î½ÎµÏ‚ Î”Ï…Î¬Î´ÎµÏ‚ (pairs)": int(len(bp)),
            "ÎœÎ±Î¸Î·Ï„Î­Ï‚ Î¼Îµ Î£Ï€Î±ÏƒÎ¼Î­Î½Î· Î¦Î¹Î»Î¯Î± (>=1)": int((bc_ps.fillna(0) > 0).sum()),
            "ÎœÎ±Î¸Î·Ï„Î­Ï‚ Î¼Îµ Î£ÏÎ³ÎºÏÎ¿Ï…ÏƒÎ· ÏƒÏ„Î·Î½ Î¯Î´Î¹Î± Ï„Î¬Î¾Î· (>=1)": int((conf_counts.fillna(0) > 0).sum()),
        })
    st.dataframe(pd.DataFrame(summary_rows).sort_values("Î£ÎµÎ½Î¬ÏÎ¹Î¿ (sheet)"), use_container_width=True)

    st.download_button(
        "â¬‡ï¸ ÎšÎ±Ï„Î­Î²Î±ÏƒÎµ ÎœÎ‘Î–Î™ÎšÎ— Î±Î½Î±Ï†Î¿ÏÎ¬ (ÏŒÎ»Î± Ï„Î± sheets)",
        data=build_mass_broken_and_conflicts_report(xl).getvalue(),
        file_name=f"mass_broken_conflicts_names_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
        type="primary"
    )
